---
title: 'DATA 624: Project 1 - Part B'
author: 'Sang Yoon (Andy) Hwang & Vinicio Haro'
date: 'October 22, 2019'
documentclass: book
subparagraph: yes
classoption: openany
output: 
  pdf_document:
    highlight: tango
    includes:
      in_header: preamble.tex
    latex_engine: xelatex
    citation_package: natbib
    keep_tex: yes
    number_sections: true
    toc: yes
    toc_depth: 2
---

# Part B: Forecasting Power {-#part-b}

```{r library-B, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, comment=FALSE}
# processing
library(readxl)

# graphs
library(ggplot2)

# formatting
library(default)
library(knitr)
library(kableExtra)
```

```{r settings-B, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, comment=FALSE}
# Set default augments for code chunks
knitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, comment=F, fig.width=10, fig.height = 3)

# Set default augments for `kable_styling()` 
default(kable) <- list("latex")
default(kable_styling)  <- list(latex_options = c("hold_position", "striped"))

# Set default for ggplot theme
default(theme) <- list(axis.text.x = element_text(angle = 90, hjust = 1),
                       axis.title.x = element_blank(),
                       axis.title.y = element_blank(),
                       plot.title = element_text(color="#B85231", size=10, face="bold"),
                       plot.subtitle = (element_text(size=8, color="#000000")),
                       legend.title = (element_text(size=10, color="#000000", face="bold")),
                       strip.background = element_rect(color="#000000", 
                                                       fill="#F5E8E4", size=1, linetype="solid"),
                       strip.text.x = element_text(size = 8, color = "#000000", face="bold"))

# GGplot Palette
default(scale_color_brewer) <- list(palette = "OrRd")
```

> **Instructions:** Part B consists of a simple dataset of residential power usage for January 1998 until December 2013.  Your assignment is to model these data and a monthly forecast for 2014.  The data is given in a single file.  The variable 'KWH' is power consumption in Kilowatt hours, the rest is straight forward.    Add these to your existing files above - clearly labeled.  

## Data Exploration and Processing {-#b-exploration}

Explore data. Process as needed. 

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(scales)
library(readxl)
library(forecast)
library(lubridate)
library(fpp2)
library(ggplot2)
library(forecast)
library(tseries)
library(imputeTS)
library(tsoutliers)
#install.packages('tsoutliers')
```

```{r warning=FALSE, message=FALSE}
#power_data <- read_excel("data/ResidentialCustomerForecastLoad-624.xlsx") 
library (readr)

power="https://raw.githubusercontent.com/vindication09/DATA-624/master/ResidentialCustomerForecastLoad-624.csv"

partb_data<-read_csv(url(power))

head(partb_data)
```

Transformed data into time-series with freq - 12.
```{r}
ts_data <- ts(partb_data$KWH, frequency = 12, start = c(1998,1))
```

Missing value check 
```{r warning=FALSE, message=FALSE}
sum(is.na(ts_data))
```

Impute Missing Data using TSImpute
```{r warning=FALSE, message=FALSE}
ts_data<-na.interpolation(ts_data)
```

Review the cycle of the time series to get an idea of the positions within the cycle. 
```{r warning=FALSE, message=FALSE}
cycle(ts_data)
```

Summary Statistics
```{r warning=FALSE, message=FALSE}
summary(ts_data)
```

```{r warning=FALSE, message=FALSE}
#disable scientific notation (ONLY RUN ONCE)
options(scipen = 99999)

autoplot(ts_data) +
labs(title = "Monthly Residential Power Usage", subtitle = "01/98 - 12/13")+
theme_classic();

ggseasonplot(ts_data);

boxplot(ts_data~cycle(ts_data),xlab="Month", ylab = "Monthly Residential Power Usage");

ggsubseriesplot(ts_data);

stl(ts_data, s.window = 'periodic') %>% autoplot();

ggAcf(ts_data);

tsoutliers(ts_data, iterate = 2, lambda = "auto")
```

Our initial plots reveal annual seasonality within this time series. The box plot/seasonality plot actually reveals where power consumption fluctuations occur within each of the cycke positions. We can speculate that this could be due to there being no major Holidays that require power draining decor plus we assume minimal AC usage during the cold months. 

We see power consumption increase between the months of June and August. This must be tied to AC usage during the warmer months of a year and finally power usage dips from September to Novemeber with a small spike in December. We speculate that thisis due to transitioning out of summer. The spike in December could be connected to the usage or Holiday lights being kept on. 

Within the overall TS plot, we see a dip in July 2010. This could be due to a power outtage during a hot summer month. This can certainly be considered to be an outlier within this TS. Using TSOutliers, we can actually identify the index where our outliers may be. TSoutliers also replaces the outlier using Box-Cox. If set lambda=auto, then TSoutliers will automatically perform Box-Cox transformation. 

The ACF plot shows that autocorrelations are well outside the significant space indicating white noise. 


## Data Model {-#b-model}

### Model #1: ARIMA
```{r warning=FALSE, message=FALSE}
arima_model <- auto.arima(ts_data)

arima_model <- forecast(arima_model, h=12)

autoplot(arima_model) + autolayer(fitted(arima_model))

checkresiduals(arima_model)
```


### Model #2: STL (no-demped) - ANN
```{r warning=FALSE, message=FALSE}
#stlf - etsmodel estimation --- A,N,N is chosen.
stl_ndemp <- stlf(ts_data, damped=FALSE, s.window = "periodic", robust=TRUE, h = 12)

# forecast plot
autoplot(stl_ndemp) + autolayer(fitted(stl_ndemp))

checkresiduals(stl_ndemp)
```

# Model #2-2: STL (demped) - AAdN
```{r warning=FALSE, message=FALSE}
#stlf - etsmodel estimation --- M, Ad, N is chosen.
stl_demp <- stlf(ts_data, damped=TRUE, s.window = "periodic", robust=TRUE, h = 12)

# forecast plot
autoplot(stl_demp) + autolayer(fitted(stl_demp))

checkresiduals(stl_demp)
```

# Model #3: ets - MNM
```{r warning=FALSE, message=FALSE}
# ETS models - MNM
ets_model <- ets(ts_data)

# forecast plot
autoplot(forecast(ets_model, h=12)) + autolayer(fitted(ets_model))

checkresiduals(ets_model)
```

Accuracy of Models
```{r warning=FALSE, message=FALSE}
accuracy(arima_model);

accuracy(stl_ndemp);

accuracy(stl_demp);

accuracy(ets_model)


```

 Out of the models we built,we can make some preliminary observations. The residuals for each of our models does not have a major deviance from normality, however Model #1: ARIMA residuals do not have an extended number of bins distorting the normality proximity. 
 
 The ACF plots show autocorrelations for each of our 4 models. Model #1: ARIMA has less autocorrelation than the other three models. Model 1 is well within the 95% limits indicated by the dotted blue lines. 
 
 If we examine the Ljung-Box test results for our models, the only model with a pvalue < 0.05 is Model #3: ets - MNM. This implies that the residuals are not independent. 


## Forecast {-#b-forecast}

We will impliment a cross validation method of testing for h=12. The process randomly chooses 12 points to measure and generate the RMSE.By definition, a lower RMSE is attributed with a better fit.

# Model #1: ARIMA
```{r warning=FALSE, message=FALSE}
arima_cv <- function(x, h){forecast(Arima(ts_data, order = c(0, 0, 1), seasonal = c(1, 1, 1),  include.drift = TRUE), h=h)}
e <- tsCV(ts_data, arima_cv, h=12)

sqrt(mean(e^2, na.rm=TRUE))
```

# Model #2: STL (no-demped) - ANN
```{r warning=FALSE, message=FALSE}
e <- tsCV(ts_data, stlf, damped=FALSE, s.window = "periodic", robust=TRUE, h=12)

sqrt(mean(e^2, na.rm=TRUE))
```

# Model #2-2: STL (demped) - AAdN
```{r warning=FALSE, message=FALSE}
e <- tsCV(ts_data, stlf, damped=TRUE, s.window = "periodic", robust=TRUE, h=12)

sqrt(mean(e^2, na.rm=TRUE))
```

Using Time series cross-validation, we compute RMSE on testset (h=12). We will pick the model with the lowest RMSE on testset as our final model. ARIMA is the worst predictor in terms of RMSE on test set (the highest RMSE) which shows that the model is seriously overfitted - low bias but very high variance. Surprisingly, STL (no-demped) - ANN, which was the worst predictor in terms of RMSE on training set, has the lowest RMSE on test set among all models. Since this is yearly forecast, tsCV(h = 12) would make sense.



## Discussion {-#b-discussion}

Given that 4 models we created did not vary much in terms of RMSE on training, while STL - ANN has significantly lower RMSE on test set than ARIMA, we will choose STL - ANN as our final model.

we found that ARIMA is the worst predictor and STL - AAN is the best model as RMSE on test set is the lowest, contradicting to its' RMSE on train set. It comes down to the discussion of bias-variance trade off; overfitted model cannot generalize the outcome of predictions on unseen data well.