---
title: 'DATA 624: Project 1'
author:
- Vinicio Haro
- Sang Yoon (Andy) Hwang
- Julian McEachern
- Jeremy O'Brien
- Bethany Poulin
date: 'October 22, 2019'
documentclass: book
subparagraph: yes
classoption: openany
output: 
  pdf_document:
    highlight: tango
    includes:
      in_header: preamble.tex
    latex_engine: xelatex
    citation_package: natbib
    keep_tex: yes
    number_sections: true
    toc: yes
    toc_depth: 2
---

# Overview {-#overview}

We split the work into three sections for Project 1. Individual team members each took lead on individual problem. Jermey and Julian focused on Part A, Sang Yoon (Andy) and Vinicio worked on Part B, and Bethany took lead on Part C.  Juliann created an overall format for the assignment to be used and all team members collectively worked together on reviewing and merging our finished product. 

## Dependencies {-#dependencies}

The following R libraries were used to complete this assignment:

```{r getting-started, echo=T, eval=T, message=F, warning=F, error=F, comment=F}
library(easypackages)

libraries('knitr', 'kableExtra', 'default')

# Processing
libraries('readxl', 'tidyverse', 'janitor', 'imputeTS', 'tsoutliers', 'lubridate')

### UNABLE TO GET JAVA TO CONFIGURE FOR >>> 'xlsx'

# Timeseries 
libraries('psych', 'urca', 'forecast', 'timetk', 'fpp2')

# Graphing
libraries('ggplot2', 'grid', 'gridExtra', 'ggfortify','ggpubr', 'scales')
```

## Data {-#data}

Data was stored within our group repository and imported below using the `readxl` package. Each individual question was solved within an R script and the data was sourced into our main report. For replication purposes, we also made our R scripts available within our appendix. All forecasts were exported and saved a `.csv` file in our [github repository]((https://github.com/JeremyOBrien16/CUNY_DATA_624/tree/master/Project%20One/) folder named forecasts.

```{r, eval=F}
# Data Aquisition
atm_data <- read_excel("data/ATM624Data.xlsx") 
power_data <- read_excel("data/ResidentialCustomerForecastLoad-624.xlsx") 
pipe1_data <- read_excel("data/Waterflow_Pipe1.xlsx")
pipe2_data <- read_excel("data/Waterflow_Pipe2.xlsx")

# Source Code
source('~/GitHub/CUNY_DATA_624/Project One/scripts/Part-A.R')
source('~/GitHub/CUNY_DATA_624/Project One/scripts/Part-B.R')
source('~/GitHub/CUNY_DATA_624/Project One/scripts/Part-C.R')
```

```{r settings-A-JM, echo=F, message=F, warning=F, error=F, comment=F}
### UNIVERSAL DATA SOURCING & DEFAULT SETTINGS FOR PROJECT

library(knitr)
library(kableExtra)
library(default)

# Load All Sourced Code Here >>> 
suppressWarnings(source("scripts/Part-A.R"))
suppressWarnings(source("scripts/Part-B.R"))
suppressWarnings(source("scripts/Part-C.R"))

# Set default augments for code chunks
knitr::opts_chunk$set(echo = F, message=F, warning=F, error=F, comment=F, fig.width=10, fig.height = 3)

# Set default augments for `kable_styling()` 
default(kable) <- list(format="latex")
default(kable_styling)  <- list(latex_options = c("HOLD_position", "striped"))
default(row_spec) <- list(row=0, bold=T)

# Set default for ggplot theme
default(theme) <- list(axis.text.x = element_text(angle = 0, hjust = NULL),
                       plot.title = element_text(color="#4c4c4c", size=12, face="bold"),
                       plot.subtitle = (element_text(size=8, color="#000000")),
                       legend.title = (element_text(size=10, color="#000000", face="bold")),
                       strip.background = element_rect(color="#000000", 
                                                       fill="#cccdd0", size=.75,linetype="solid"),
                       strip.text.x = element_text(size = 8, color = "#000000", face="bold"))

# GGplot Palette
default(scale_color_brewer) <- list(palette = 'RdPu', direction=1)
```


# Part A: ATMs

>  **Instructions:** In part A, I want you to forecast how much cash is taken out of 4 different ATM machines for May 2010.  The data is given in a single file.  The variable `Cash` is provided in hundreds of dollars, other than that it is straight forward.  I am being somewhat ambiguous on purpose.  I am giving you data, please provide your written report on your findings, visuals, discussion and your R code all within a Word readable document, except the forecast which you will put in an Excel readable file.  I must be able to cut and paste your R code and run it in R studio.  Your report must be professional - most of all - readable, EASY to follow.  Let me know what you are thinking, assumptions you are making!  Your forecast is a simple CSV or Excel file that MATCHES the format of the data I provide.

## Exploration

The data covers a period of Friday May 1, 2010 through Saturday April 30, 2010. While reviewing the data, we identified that the original data file contained `NA` values in our `ATM` and `Cash` columns for 14 observations between May 1 and 14, 2010. As these contain no information, we removed these missing values and transformed the dataset into a wide format. 

```{r, include=F}
#SILENCED CODE CHUNK FOR DISCUSSION
# Box plot hard to view and interpret with large outlier. Suggest either removing outlier or
# deleting plot.

# Examine distribution of values to identify outliers
atm_data %>% 
  group_by(ATM) %>% 
  ggplot(aes(x = ATM, y = Cash,fill=ATM)) +
  geom_boxplot() +
  labs(title="ATM Boxplot",x="", y="Cash (in hundreds)") +
  theme_bw() +
  theme(legend.position = 'none', 
        axis.text.x = element_text(angle = 45, 
                                   hjust = 1)) +
  scale_fill_brewer(palette = 'RdPu')
```

Our initial review also revealed that ATM2 contained one missing value on 2009-10-25 and that ATM4 contained a potential outlier of \$1,123 on 2010-02-09. We replaced both values with the corresponding mean value of each machine. 

We examined summary statistics for each ATM time series:  

+  ATM1 and ATM2 have pretty normal distributions; ATM1's daily mean cash dispensed is \$84, and ATM2's is \$62. 
+  ATM3 only dispensed cash on the last three days of the time series - as this provides few data points on which to forecast, we'll need to treat it specially. 
+  ATM4 has a similar mean to ATM1, but skew and kurtosis suggest the impact of an outlier Wednesday, February 10, 2010.  If this ATM is located in the Northeastern United States, this may have a relationship to a blizzard which struck on that day.  

```{r}
# plot atms as scatterplot
atm %>% 
  # re-gather observations for facet plot
  gather(key=ATM, value=Cash, ATM1,ATM2, ATM3,ATM4) %>% 
  # remove NA value from ATM2
  filter(complete.cases(.)) %>% 
  # plot 
  ggplot(aes(DATE, Cash, color=ATM)) +
  geom_point() +
  geom_smooth(method="loess") +
  facet_wrap(~ATM, scales='free_x', nrow=1) +
  labs(title="ATM Scatterplot",x="", y="Cash (in hundreds)")+
  theme_bw()+
  theme(legend.position = 'none', axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_color_brewer()
```

Last, we used a scatterplot to examine the correlation between cash withdrawals and dates for each machine.  We identified similiar patterns between ATM1 and ATM4, which show non-linear fluctuations that suggest a potential trend component in these timeseries. ATM2 follows a relatively linear path and decreases overtime. This changes in the last few observations, where withdrawals begin to increase. As mentioned, there are only 3 observed transactions for ATM3 that appear at the end of the captured time period. 

### Timeseries Plots 

Our cleaned dataframe was then converted into a timeseries format. The time series plots show high weekly variance, for ATM1, ATM2, and ATM4 - consistent with our takeaway from the scatterplots. 

These plots also remind us that ATM3 only dispensed cash on 3 days at the end of the timespan, with a daily range between \$82 and \$96.  Given the paucity of observations in the training data, the simplest possible approach to forecasting ATM3, averaging, is likely best.  Given that ATM3 distributed no cash until April 28, 2010, we'll assume that it was not operating until then and only include the three day window of non-zero observations in the forecast.

```{r, fig.height=5}
autoplot(atm_ts, facets = T)+
  geom_line(color="#4B0082")+
  labs(title = "Daily ATM Transactions", 
       subtitle = "Series: ATM1", y="Cash (in hundreds)", x="Weeks")+
  theme_bw()+ theme()
```

## Evaluation 

We constructed our initial timeseries for ATM1, ATM2, and ATM4 using a weekly frequency. Our ACF plots for each ATM showcases large, decreasing lags starting at 7. This pattern continues in a multiple of seven, which confirms our assumption about seasonality within the observed data. These lags are indicative of a weekly pattern. 
\newline

```{r fig.height=4}
p1<-ggAcf(ATM1_ts, color = 'darkorange4')+ labs(title="ACF: ATM1")+ theme_bw()+theme()
p2<-ggPacf(ATM1_ts,color = 'darkorange4')+ labs(title="PACF: ATM1")+ theme_bw()+ theme()
p3<-ggAcf(ATM2_ts,color = 'darkorange4')+ labs(title="ACF: ATM2")+ theme_bw()+theme()
p4<-ggPacf(ATM2_ts,color = 'darkorange4')+ labs(title="PACF: ATM2")+ theme_bw()+ theme()
p5<-ggAcf(ATM4_ts,color = 'darkorange4')+ labs(title="ACF: ATM4")+ theme_bw()+theme()
p6<-ggPacf(ATM4_ts,color = 'darkorange4')+ labs(title="PACF: ATM4")+ theme_bw()+ theme()

grid.arrange(grob=p1, p3, p5, p2, p4, p6, ncol=3)
```

Our plots further suggest that the ATM data is non-stationary. We performed a unit root test using the `ur.kpss()` function to confirm this observation. The test results below show that differencing is required on all ATM2 and ATM4 series. ATM1 falls just below the cut-off critical value, but could still benefit from differencing due to the observed seasonal pattern.   

```{r}
urATM1<-cbind("ATM"="ATM1", "No-Diff"=round(ATM1_ur@teststat,4),"Diff-1" =round(ATM1d_ur@teststat,4))

urATM2<-cbind("ATM"="ATM2", "No-Diff"=round(ATM2_ur@teststat,4),"Diff-1" =round(ATM2d_ur@teststat,4))

urATM4<-cbind("ATM"="ATM4", "No-Diff"=round(ATM4_ur@teststat,4),"Diff-1" =round(ATM4d_ur@teststat,4))

rbind(urATM1, urATM2,urATM4) %>% kable(caption="KPSS unit root test") %>% kable_styling() %>% row_spec()
```

## Modeling 

We used `auto.arima()` and set `D=1` to account for seasonal differencing of our data to select the best ARIMA models for ATM1, ATM2, and ATM4. The full models and accuracy statistics for each series can be viewed in the appendix.

*  **ATM1**: ARIMA$(0,0,2)(0,1,1)_7$ 
*  **ATM2**: ARIMA$(2,0,2)(0,1,1)_7$
*  **ATM3**: MEAN
*  **ATM4**: ARIMA$(0,0,2)(0,1,1)_7$ 

The residual ACF plots contain no pattern and the lags fall within the critical value, which suggest they are white noise and not autocorrelated. Further, the residual histograms follow a relatively normal distribution, which confirms that the models adequately fits the observed data. 

```{r}
p1<-ggAcf(ATM1_AA$residuals, lag=21, color = 'darkorange4')+ labs(title="ATM1", x="Lag", y="") +theme_bw()+theme()
p2<- ggpubr::gghistogram(ATM1_AA$residuals, fill="peachpuff1")+
  labs(title="ATM1", subtitle="ARIMA(0,0,2)(0,1,1)[7]",x="")+
  theme_bw()+theme()
p3<-ggAcf(ATM2_AA$residuals, lag=21,color = 'darkorange4')+ labs(title="ATM2",x="Lag", y="") +theme_bw()+theme()
p4<-ggpubr::gghistogram(ATM2_AA$residuals,  fill="lightpink")+
  labs(title="ATM2", subtitle="ARIMA(2,0,2)(0,1,1)[7]",x="")+
  theme_bw()+theme()
p5<-ggAcf(ATM4_AA$residuals, lag=21,color = 'darkorange4')+ labs(title="ATM4",x="Lag", y="") +theme_bw()+theme()
p6<-ggpubr::gghistogram(ATM4_AA$residuals,fill="deeppink4")+
  labs(title="ATM4", subtitle="ARIMA(0,0,2)(0,1,1)[7]", x="")+
  theme_bw()+theme()

grid.arrange(grob=p1, p3, p5, ncol=3, top=textGrob(label="ACF Plots of Residuals"))
             
grid.arrange(p2, p4, p6, ncol=3, top=textGrob(label="Histograms of Residuals"))
```

## Forecast

A forecast for the month of May will be 31 days in length. We applied a forecast to each series, which spanned across 5 weeks. The numeric forecasts can be viewed in a table output in the appendix section and are also located within our data output folder.   

```{r, fig.height=10}

p1<-autoplot(ATM1_AA$fitted)+autolayer(ATM1_fc, color="peachpuff1")+
  coord_cartesian(xlim = c(1, 57.5))+
  labs(title = "ATM1 Series", x="Weeks", y="Cash")+theme_bw()+theme()+
  scale_x_continuous(breaks=seq(1,60,by=3))

p2<-autoplot(ATM2_AA$fitted)+autolayer(ATM1_fc,  color="lightpink")+
  coord_cartesian(xlim = c(1, 57.5))+
  labs(title = "ATM2 Series", x="Weeks", y="Cash")+theme_bw()+theme()+
  scale_x_continuous(breaks=seq(1,60,by=3))

p3<-ATM3_plotdata %>% 
  ggplot()+
  geom_line(aes(x = Date/7, y = Cash))+
  geom_line(aes(x = Date/7, y=`Point Forecast`))+
  geom_ribbon(aes(x = Date/7, ymin = `Lo 95`, ymax = `Hi 95`), linetype = 'blank', fill = 'deeppink4', alpha = .4)+
  geom_ribbon(aes(x = Date/7, ymin = `Lo 80`, ymax = `Hi 80`), linetype = 'blank', fill = 'deeppink4', alpha = .2)+
  coord_cartesian(xlim = c(1, 57.5))+
  labs(title = "ATM3 Series", x="Weeks", y="Cash")+theme_bw()+theme()+
  scale_x_continuous(breaks=seq(1,60,by=3))

p4<-autoplot(ATM4_AA$fitted)+autolayer(ATM1_fc, color="darkorchid4")+
  coord_cartesian(xlim = c(1, 57.5))+
  labs(title = "ATM4 Series", x="Weeks", y="Cash")+theme_bw()+theme()+
  scale_x_continuous(breaks=seq(1,60,by=3))

grid.arrange(p1, p2, p3, p4, ncol=1, top=textGrob(label="ATM Forecasts"))
```

## Summary

Jeremy & Juliann - synthesize findings


# Part B: Forecasting Power

> **Instructions:** Part B consists of a simple dataset of residential power usage for January 1998 until December 2013.  Your assignment is to model these data and a monthly forecast for 2014.  The data is given in a single file.  The variable 'KWH' is power consumption in Kilowatt hours, the rest is straight forward.    Add these to your existing files above - clearly labeled.  

## Exploration

We observed there was a missing value in September 2008. We used imputation method called na.interpolation which performs a technique in numerical analysis which estimates a value from known data points. For our case, linear method using first order Taylor polynomial is used.

### Timeseries Plot 

```{r}
# time series plot
autoplot(ts_data) +
labs(title = "Monthly Residential Power Usage", subtitle = "Time Series: 01/98 - 12/13", y = "KWH (in Millions)")+
theme_bw()+theme()+scale_y_continuous(label = unit_format(unit = "m", scale = 1e-6))
```

Our initial time series plot reveal annual seasonality within this time series. The box plot/seasonality plot actually reveals where power consumption fluctuations occur within each of the cycle positions. We can speculate that this could be due to there being no major Holidays that require power draining decor plus we assume minimal AC usage during the cold months. 

## Evaluation 

We see power consumption increase between the months of June and August. This must be tied to AC usage during the warmer months of a year and finally power usage dips from September to Novemeber with a small spike in December. We speculate that thisis due to transitioning out of summer. The spike in December could be connected to the usage or Holiday lights being kept on. 

Within the overall TS plot, we see a dip in July 2010. This could be due to a power outtage during a hot summer month. This can certainly be considered to be an outlier within this TS. Using TSOutliers, we can actually identify the index where our outliers may be. TSoutliers also replaces the outlier using Box-Cox. If set lambda=auto, then TSoutliers will automatically perform Box-Cox transformation.

The ACF plot shows that autocorrelations are well outside the significant space indicating the series is not white noise, non-stationary. 

```{r, fig.height=6}
# season plot
p1 <- ggseasonplot(ts_data)+
  labs(title="Seasonal Plot")+theme_bw()+theme(legend.position = 'none')+
  scale_y_continuous(label = unit_format(unit = "m", scale = 1e-6))

# sub-season plot
p2 <- ggsubseriesplot(ts_data)+labs(title="Subseries Plot", y="")+theme_bw()+theme()+
  scale_y_continuous(label = unit_format(unit = "m", scale = 1e-6))

# ggAcf
p3 <- ggAcf(ts_data,color = 'darkorange4')+labs(title="ACF Plot", y="")+theme_bw()+theme()

# STL decomposition
p4 <- autoplot(stl1)+theme_bw()+theme()+scale_y_continuous(label = unit_format(unit = "m", scale = 1e-6))

grid.arrange(grob=p1, p2, p3, p4, ncol=2,   
             layout_matrix = rbind(c(1, 4),
                                   c(2, 4),
                                   c(3, 4)),
             top=textGrob(label="Diagnostic Plots"))
```

## Modeling

Out of the models we built, we can make some preliminary observations. The residuals for each of our models does not have a major deviance from normality, however residuals of Model #1: ARIMA do not have an extended number of bins distorting the normality proximity but we can say it is still fairly normally distributed. 
 
The residual ACF plots show residual autocorrelations for each of our models. Model #1: ARIMA has less autocorrelation than the other three models. Model 1 is well within the 95% limits indicated by the dotted blue lines. 
 
If we examine the Ljung-Box test results for our models, the only model with a p-value > 0.05 is Model #1: ARIMA. This implies that the residuals from other models are not independent, hence not white noise. The full model summary can be viewed in the appendix.

### Model #1: ARIMA

```{r warning=FALSE, message=FALSE}
checkresiduals(arima_fc)
```

### Model #2: STL (no-demped) - MNN

```{r}
checkresiduals(stl_ndemp)
```

### Model #2-2: STL (demped) - MAdN

```{r}
checkresiduals(stl_demp)
```

### Model #3: ets - MNM
```{r}
checkresiduals(ets_model)
```

## Forecast

The `auto.arima()` function performs cross validation on hyperparameter tuning to find the best model with parameters  of `order` and `seasonal` that minimize `AIC`. This gave us **arima_model**: ARIMA$(3,0,2)(2,1,0)12$ with drift resulting `AIC` = 5332.24. 

Since ARIMA is the only reliable model, as other models failed Ljung test, we will plot forecasts of ARIMA only. The forecasted values can be viewed in the appendix. 

### Model #1: ARIMA

```{r}
autoplot(arima_fc)+
  scale_y_continuous(label = unit_format(unit = "m", scale = 1e-6))+ 
  labs(title="Forecast: Residential Power - Model 1", subtitle="ARIMA(3,0,2)(2,1,0)[12] with drift", y = "KWH (in Millions)")+theme_bw()+theme()

## unable to get autoplot autolayer working :(
## Error: Invalid input: date_trans works with objects of class Date only

#forecast::autoplot(arima_fc)+forecast::autolayer(arima_auto$fitted, series="Fitted")
#  labs(y = "KWH (in Millions)")+
#  theme_classic()+theme(legend.position = 'bottom')+
#  scale_y_continuous(label = unit_format(unit = "m", scale = 1e-6))
```

## Summary 

We implemented a cross validation method of testing for `h=12`. The process randomly chooses 12 points to measure and take the average of RMSEs. By definition, a lower RMSE on test set is attributed with a better forecast on unseen data. 

Using Time series cross-validation, we compute RMSE on testset (`h=12`). We would have to pick the model with the lowest RMSE on test set as our final model if we had more than 1 model to compare. In our case, since we only have 1 model left after Ljung test, we  have no choice but to pick seasonal ARIMA model as our final choice. Cross-validation test shows that RMSE on test is around 720k when RMSE on training is around 589k. We can conclude the model is not necessarily overfitted. Given that MAPE on training is less than 7, it is not a suprising result.

```{r}
paste("RMSE - train:",rmse_train_arima) 
paste("RMSE - test:",rmse_test_arima)
```



# Part C: Waterflow

>  **Instructions:** Part C consists of two data sets.  These are simple 2 columns sets, however they have different time stamps.  Your optional assignment is to time-base sequence the data and aggregate based on hour (example of what this looks like, follows).  Note for multiple recordings within an hour, take the mean.  Then to test appropriate assumptions and forecast a week forward with confidence bands (80 and 95%). Add these to your existing files above - clearly labeled.  

## Exploration

Because of the disparities in the data some grooming was necessary:  

**Pipe one:**  
* 1000 observations
* No missing values 
* Multiple reading within each hour  
* 9-days of data  
 
**Pipe Two**  
* 100 Observations  
* No missing values 
* Single reading on the hour 
* 41-days of data  
 
For Pipe One, representing 9-days of water flow rate measurements multiple samples per hour, a mean of all rates in the hour was taken and labeled with the whole-hour at the beggining of the period (floor hour) to align with the hourly readings from Pipe Two. After aggregating, there were only 236 observations (spanning 9-days) of pipe one and still 1000 observations (spanning 41-days) from Pipe Two.    

Both data sets posed an interesting conundrum. With two possible ways of handling it:

1. Merge the files, and use only 236 observations. 
  + All forecasts would be based on the combined data. 
  + This would mean making 168 forecasts with only 236 data-points prior. 
  + All forecasts would be starting November 1, instead of from the end of data: December 3.   
2. Merge the files and use the whole set to make predictions.  
  + We would have 100 observations to model prior to forecasts. 
  + 236 of the observations would be be different from the remaining 764, which could both alter the model type and forecast. 
  + We would be forecasting from the natural ending of the Pipe Two readings  

Because it was concievable that there might be a daily periodicity, it was important to have a frequency of 24, which made numbering by day of year and grooming the time series to start on the 7081 hour aligning with October 23 01:00 AM.


### Timeseries Plots 

```{r}
w1plot<-autoplot(w1,colour ='peachpuff')+
  labs(title = "Pipe One Flow Rates", subtitle = 'October 23, 2015 - November 1, 2015', y="Flowrate", x="Days")+
  theme_bw()+ theme()

w2plot<-autoplot(w2,colour ='lightpink')+
  labs(title = "Pipe Two Flow Rates", subtitle = 'October 23, 2015 - December 23, 2015',
       y="Flowrate", x="Days")+ theme_bw()+ theme()

wsplot<-autoplot(ws, colour ='deeppink4')+labs(title = "Combined Pipe Flow Rates", subtitle = 'October 23, 2015 - December 23, 2015', y="Flowrate", x="Days")+ theme_bw()+ theme()

grid.arrange(grob=w1plot, w2plot, wsplot, ncol=3)
```  

## Evaluation

### Decomposition  

It is clear from the combined plot that there is a pretty notable change in the trend when the readings from Pipe One wane. Let's look at the decomposed seriesand see if it gives us some insight into a good model.

```{r, fig.height=5}
ws_decomp
```
From the decomposition, the appears to be a seasonal component in agreement with the assessment that there might be a daily flowrate periodicity. Also, as expected, around day 306 where Pipe One flow rates go silent there is a trend down and then relatively flat trend thereafter. 

### Estimating Stationarity

Number of Estimated Differences: `r ws_diffs`

```{r echo=FALSE}
tseries::adf.test(ws) 
```

Here we have contradictory esitmates, `ndiffs()` suggests a difference of 1, and the augmented dicky fuller test suggests that we are stationary as-is. An `auto.arima()` may give us a reasonable starting place.

### Estimating  Orders for ARIMA

#### Interpreting the ACF and PACF

```{r}
grid.arrange(ws_acf, ws_pacf, nrow=1)
```  

The ACF remain wholly above the critical threshold, so will likely require differencing as suggested by the `ndiffs()`, in looking at the PACF, there is some abiguity caused by the needed differencing, but after the intial trend down below the critical threshold, there is definitely a slight spike at 24, which would suggest there may indeed by a daily period or season we need to account for in our forecast.

#### Differenced ACF

```{r}
grid.arrange(ws_acf_diff, ws_pacf_diff, nrow=1)
```   

A final ACF of the differenced data was done to ensure that a seconf first-order difference was not needed; thus we assume $d = 1$, a but it was not so clear about the appropriate value of $q4 should it be 5? , so `auto.arima()` is in order to help iterate up on the likely best starting place

## Modeling 

The `auto.arima()` function was used in model selection. Using a Box-Cox lambda value to normalize the data may make $\lambda= .931552$. Because models can vary a lot based on the selection criterion, both BIC and AIC models were run, using lambda, to estimate a good starting place. We included the transformations in the model (instead of doing it outside the model), because we are using the ARIMA function to difference the data automatically allow more constiency and flexibility in testing other model orders.

The *AICc* chose a seasonal ARIMA of the following order:

$ARIMA(1,1,3)(0,0,1)[24]$ 
*AIC=7359.84   AICc=7359.9   BIC=7384.38*

The *BIC* chose a non-seasonal ARIMA model as follows:   

$ARIMA(2,1,1)$ 
*AIC=8082.22   AICc=8082.26   BIC=8101.85*

In both cases, the arima estimated that there needed to be differencing which was supported by `ndiffs()` and our ACF & PACF plots. 

In comparing the two forecasts, for these automated models, they both degrade toward the series mean pretty quickly, however, the AICc model makes forecasts which consider the variation of the model a bit better before it levels out. So we decided to explore this model and see if we could tune it to provide more robust predictions

**AIC $ARIMA(1,1,3)(0,0,1)[24]$ Residual Plots**   

```{r}
# aic_plot <- aic_plot
aic %>% checkresiduals()
```

**BIC $ARIMA(2,1,1)$ Residual Plots**   


```{r, echo = FALSE}
# bic_plot <-bic_plot

bic  %>% checkresiduals()
    
# 
# grid.arrange(grob= aic_plot,  bic_plot,  ncol=2)
```


### Interpreting `auto.arima()`

In looking at the AICc and BIC ARIMA models, the both appear to be relatively white-noisy with no autocorrelation on the first or 24th observations, with relatively normal residuals. However, in looking at the Ljung-Box test for independence, it is clear that the Seasonal $ARIMA (1,1,3)(0,0,1)[24]$ is independent, where the $ARIMA(2,1,1)$ is not, thus reaffirming the lingering suspicion that thee is unaccounted for seasonal variation in the model requiring a seasona MA(1) to rectify. To be sure that the best model has been found, p & q as well as Q will be varied to see if a slight modification improves the performance of the model.

### Manual ARIMA testing

```{r, echo = FALSE}
(fit <- Arima(ws, order=c(1,1,3), seasonal=c(0,0,1),
  lambda=lambda))
checkresiduals(fit, lag=36)
```  


## Forecast 


### $ARIMA(1,1,3)(0,0,1)[24]$

```{r, echo = FALSE}
Arima(ws, order=c(1,1,3), seasonal=c(0,0,1),lambda=lambda)%>%
  forecast() %>%
  autoplot() +
    ylab("Water Flow Rate") + xlab("Year")
```   

### $ARIMA(2,1,3)(0,0,1)[24]$

```{r, echo = FALSE}
(fit <- Arima(ws, order=c(2,1,3), seasonal=c(0,0,1),
  lambda=lambda))
checkresiduals(fit, lag=36)
```    

This Ljung-Box  shows  unexplained variances in the residuals indicating that this model is not yet fully realized and inferior to the Seasonal $ARIMA (1,1,3)(0,0,1)[24]$.

```{r, echo = FALSE}
(fit <- Arima(ws, order=c(1,1,2), seasonal=c(0,0,1),
  lambda=lambda))
checkresiduals(fit, lag=36)
```    

This Ljung-Box also shows unexplained variances in the residuals indicating that this model is not yet fully realized and inferior to the Seasonal $ARIMA (1,1,2)(0,0,1)[24]$.

```{r, echo = FALSE}
(fit <- Arima(ws, order=c(1,1,3), lambda=lambda))
checkresiduals(fit, lag=36)

```      

This Ljung-Box also shows unexplained variances in the residuals indicating that this model is not yet fully realized and inferior to the Seasonal $ARIMA (1,1,3)$.

### Accepting the `auto.arima()`

Given that the other models show unexplained variance in the residuals, the final predictions will be made using the AICc recommended model of $ARIMA (1,1,3)(0,0,1)[24]$.

```{r, echo = FALSE}

autoplot(subset(ws, start=950))+
    autolayer(forecast(final_ws), color="darkorchid")

```

### Forecast Accuracy  

`r accuracy(forecast(fit))%>%knitr::kable()`  


## Summary

Ultimately this model is marginally useful as seen by the Mean Absolute Percentage of Error which reveals that the average percentage each forecast is off by is around 50%. In looking at the graph of the forecast above, which is the last 150 points in the time series and the forecasted points, you can see this as the predictions lightly modulate around the mean and deteriorate to it pretty quickly.

In looking at the original decomposition, there very little trend, a lot of seasonality, is a pretty substatial amount of random noise, which is not considered in the model, and is responsible for the majority of the error in this model, as white noise is never predictable.

# Appendix A {-#appendix-a}

### ARIMA Model Summary {-#arima-a}

**`ATM1`:**
```{r}
ATM1_AA
```

**`ATM2`:**
```{r}
ATM2_AA
```

**`ATM4`:**
```{r}
ATM4_AA
```

### Point Forecasts {-#forecast-a}

```{r}
ATM_FC %>% mutate(ATM1=as.numeric(as.character(ATM1)),
                  ATM2=as.numeric(as.character(ATM2)),
                  ATM3=as.numeric(as.character(ATM3)),
                  ATM4=as.numeric(as.character(ATM4))) %>%
  kable(caption="ATM Mean Point Forecast",digits=2) %>% kable_styling(full_width = T) %>% row_spec()
```

\newpage
### R Script {-#script-a}

```{r, echo=T, eval=F}
# Load data
atm_data <- read_excel("data/ATM624Data.xlsx") 

# clean dataframe
atm <- atm_data %>% 
  # create wide dataframe
  spread(ATM, Cash) %>% 
  # remove NA column using function from janitor package
  remove_empty(which = "cols") %>%
  # filter unobserved values from May 2010 
  filter(DATE < as.Date("2010-05-01")) %>% arrange(DATE) 

atm$ATM2[is.na(atm$ATM2)] <- mean(atm$ATM2, na.rm = TRUE) ## remove NA
atm$ATM4[which.max(atm$ATM4)] <- mean(atm$ATM4, na.rm = TRUE) ## remove outlier

# create TS with weekly frequency & subset data
atm_ts <- atm %>% select(-DATE) %>% ts(start=1,  frequency = 7)
ATM1_ts <- atm_ts[,1]; ATM2_ts <- atm_ts[,2]; ATM3_ts <- atm_ts[,3]; ATM4_ts <- atm_ts[,4]

#unit root test: 
ATM1_ur <-ur.kpss(ATM1_ts); ATM2_ur <-ur.kpss(ATM2_ts); ATM4_ur <-ur.kpss(ATM4_ts)
ATM1d_ur <-ur.kpss(diff(ATM1_ts, lag=7)); ATM2d_ur <-ur.kpss(diff(ATM2_ts, lag=7))
ATM4d_ur <-ur.kpss(diff(ATM4_ts, lag=7))

# AUTO.ARIMA function; set D=1 for seasonal differencing
ATM1_AA <-auto.arima(ATM1_ts, D = 1, lambda = "auto", approximation = F, stepwise = T)
ATM2_AA <-auto.arima(ATM2_ts, D = 1, lambda = "auto", approximation = F, stepwise = T)
ATM4_AA <-auto.arima(ATM4_ts, D = 1, lambda = "auto", approximation = F, stepwise = T)

# Forecast Results
ATM1_fc <- forecast(ATM1_AA,h=31); ATM2_fc <- forecast(ATM2_AA,h=31)
ATM3_fc <- meanf(ATM3_ts[ATM3_ts > 0], h=31); ATM4_fc <- forecast(ATM4_AA,h=31)

# Prepare dataframe for ATM3 mean forcast plotting 
ATM3_plotdata_fc <- cbind(seq(from = 366, to = 396), ATM3_fc[[5]], ATM3_fc[[6]], 
                          ATM3_fc[[7]]) %>% as.data.frame()

colnames(ATM3_plotdata_fc) <- c('Date', 'Point Forecast', 
                                'Lo 80', 'Lo 95', 'Hi 80', 'Hi 95')
ATM3_plotdata <- ATM3_ts %>% fortify() %>% select(-Index) %>% rename(Cash = Data) %>% 
  mutate(Date = as.numeric(row.names(.))) %>% select(Date, Cash) %>% 
  full_join(ATM3_plotdata_fc, by = 'Date')

#Revert results back into original form
date <- as.character(seq(as.Date('2010-05-01'), length.out=31, by=1))
ATM_FC <-  cbind("Date"=date, "ATM1"=ATM1_fc$mean, "ATM2"=ATM2_fc$mean,
                 "ATM3"=ATM3_fc$mean,"ATM4"=ATM4_fc$mean) %>% as.data.frame()

write_csv(ATM_FC, path = "forecasts/ATM_all_forecast.csv")
```

# Appendix B {-#appendix-b}

### Model Summary {-#model-b}

**`ARIMA`:**
```{r}
summary(arima_auto)
```

**`STL - MNN`:**
```{r}
summary(stl_ndemp)
```

**`STL - MAdN`:**
```{r}
summary(stl_demp)
```

**`ets - MNM`:**
```{r}
summary(ets_model)
```

### R Script {-#script-b}
```{r, echo=T, eval=F}
library(readxl)
library(tidyverse)
library(forecast)
library(imputeTS)
library(tsoutliers)

# load data
power_data <- read_excel("data/ResidentialCustomerForecastLoad-624.xlsx")
# Time Series
ts_data <- ts(power_data$KWH, frequency = 12, start = c(1998,1))
# Missing value imputation
ts_data <- na_interpolation(ts_data)
# STL decomposition
stl1 <- stl(ts_data, s.window = 'periodic')
# Handling outlier
outlier_func <- tsoutliers(ts_data, iterate = 2, lambda = "auto")

# Time Series - After outlier and imputation handeled
ts_data_o <- ts_data  # Let's treate outlier handled data seperatly for Modelling part.
ts_data_o[outlier_func$index] <- outlier_func$replacements

# Model#1: ARIMA
arima_auto <- auto.arima(ts_data_o)
arima_fc <- forecast(arima_auto, h=12)

# Model #2: STL (no-demped) - MNN
stl_ndemp <- stlf(ts_data_o, s.window = "periodic", robust=TRUE, h = 12)

# Model #2-2: STL (demped) - MAdN
stl_demp <- stlf(ts_data_o, damped=TRUE, s.window = "periodic", robust=TRUE, h = 12)

# Model #3: ets - MNM
ets_auto <- ets(ts_data_o)
ets_model <- forecast(ets_auto, h=12)

# tsCv - ARIMA -> it takes so much time. I got the results and saved them
##arima_cv <- function(x, h){forecast(Arima(x, order = c(3, 0, 2), 
## seasonal = c(2, 1, 0), include.drift = TRUE), h=h)}
##e <- tsCV(ts_data_o, arima_cv, h=12)

# RMSEs -> tsCV takes lot of time to process so just saved the output
#rmse_train_arima <- arima_auto[2]
#rmse_test_arima <- sqrt(mean(e^2, na.rm=TRUE))
rmse_train_arima <- 589381.7
rmse_test_arima <- 725175

# Save output
write.csv(arima_fc, file="forecasts/POWER_ARIMA_FC.csv")
```

# Appendix C {-#appendix-c}

### Sample Forecasts {-#sample-forecast-c}
```{r, echo = FALSE}
head(preds_ws, 30)%>%
  knitr::kable(caption = 'First few predictions in the set')%>%
  kable_styling()
```  

\newpage

### R-Script {-#script-c}

```{r echo=T, eval=F}
library(tidyverse)
library(readxl)
library(fpp2)
library(forecast)
library(lubridate)
library(psych)
#library(xlsx)
options(scipen = 999)

# Reading Data
waterflow_1 <- read_excel("data/Waterflow_Pipe1.xlsx")
waterflow_2 <- read_excel("data/Waterflow_Pipe2.xlsx")

# Writing original data to submission file
#file ='forecasts/water-pipes.xlsx'
#write.xlsx(waterflow_1, file =  file , sheetName ="Waterflow Pipe 1", col.names = TRUE, row.names = TRUE, append = FALSE)
#write.xlsx(waterflow_2, file=file, sheetName = "Waterflow Pipe 2", col.names = TRUE, row.names = TRUE, append = TRUE)

# Grooming, aligning dates and aggregating Data
waterflow_1<-waterflow_1 %>% 
    mutate(DateTime = as.POSIXct(DateTime))%>%
    group_by(hour=floor_date(DateTime, "hour")) %>%
    summarize(WaterFlow=mean(WaterFlow))


waterflow_2<-waterflow_2 %>% 
    mutate(DateTime = as.POSIXct(DateTime))%>%
    group_by(hour=floor_date(DateTime, "hour")) %>%
    summarize(WaterFlow=mean(WaterFlow))

# Creating a combined data set
waterflow_all <-merge(waterflow_1, waterflow_2, by = 'hour', all = TRUE)%>%
    mutate(waterflow = rowSums(.[c("WaterFlow.y", "WaterFlow.x")], na.rm = TRUE))%>%
    select(hour, waterflow)

# Converting all Three Data Sets to Time Series
w1<-ts(waterflow_1$WaterFlow ,start=c(1,7081),frequency=24)
w2<-ts(waterflow_2$WaterFlow ,start=c(1,7081),frequency=24)
ws <- ts(waterflow_all$waterflow ,start=c(1,7081),frequency=24)


#Decomposition of Time Series
ws_decomp<- ws%>% 
    decompose()%>%
    autoplot()+
    labs(title = "Decomposition of Hourly Waterflow Data",
         subtitle = 'First Reading October 23, 2015',
         x = 'Day of Year')+
    theme_bw()


# Checking Differences
ws_diffs<- ws%>%
    ndiffs() #1


# Testing Stationarity
dickie<-tseries::adf.test(ws)

# ACF & PACF

ws_acf <- ggAcf(ws, color = 'darkorange4')+
    labs(title = "ACF Combined Pipe Flow Rates", 
         subtitle = 'October 23, 2015 - December 23, 2015',
         y="Auto Correlation", x="Hours")+
    theme_bw()+ theme()

ws_pacf <- ggPacf(ws, color = 'darkorange4')+
    labs(title = "PACF Combined Pipe Flow Rates", 
         subtitle = 'October 23, 2015 - December 23, 2015',
         y="Partial Auto Correlation", x="Hours")+
    theme_bw()+ theme()

# Differencesd ACF & PACF

ws_acf_diff <-ggAcf(diff(ws,lag = 1), color = 'darkorange4')+
    labs(title = "ACF Combined Pipe Flow Rates", 
         subtitle = 'October 23, 2015 - December 23, 2015',
         y="Auto Correlation", x="Hours")+
    theme_bw()+ theme()

ws_pacf_diff <-ggPacf(diff(ws,lag = 1), color = 'darkorange4')+
    labs(title = "PACF Combined Pipe Flow Rates", 
         subtitle = 'October 23, 2015 - December 23, 2015',
         y="Auto Correlation", x="Hours")+
    theme_bw()+ theme()

#Establishing a lambda value for ARIMA transformations
lambda <-  BoxCox.lambda(ws)
#Lambda = 0.9531552


# Auto arima's including season components for AICc and BIC
aic<- auto.arima(ws, seasonal = TRUE, ic = 'aicc', lambda = lambda)

bic<-auto.arima(ws, seasonal = TRUE, ic = 'bic', lambda = lambda )


# Plots of auto.arimas
aic_plot <- auto.arima(ws, seasonal = TRUE, ic = 'aicc', lambda = lambda)%>%
    forecast(h=24*7)%>%
    autoplot() +
    labs(title = "AIC selected ARIMA(1,1,3)(0,0,1)[24] ", 
                 subtitle = 'October 23, 2015 - December 23, 2015',
                y="Flowrate", x="Days")+
    theme_bw()+ theme()

    
bic_plot<-auto.arima(ws, seasonal = TRUE, ic = 'bic', lambda = lambda )%>%
    forecast(h=24*7)%>%
    autoplot()+
    labs(title = "BIC selected ARIMA(2,1,1)  ", 
         subtitle = 'October 23, 2015 - December 23, 2015',
         y="Flowrate", x="Days")+
    theme_bw()+ theme()


# Final AIC from AICc and predictions
final_ws <- Arima(ws, order=c(1,1,3), seasonal=c(0,0,1),lambda=lambda)

preds_ws <-as.data.frame(forecast(final_ws, h = 168))


#Renaming fields for output data
waterflow_all <-waterflow_all%>%
    rename( DateTime = hour,
            WaterFlow = waterflow)
# Formatting forecasts for output data    
preds_ws<-preds_ws%>%
    mutate(DateTime = seq(from=as.POSIXct("2015-12-3 17:00", tz="UTC"),
                          to=as.POSIXct("2015-12-10 16:00", tz="UTC"), 
                          by="hour") )%>%
    select(DateTime, `Point Forecast`, `Lo 80`,`Hi 80`, `Lo 95`, `Hi 95`)

# Writing forecasts and final data to the 'XLSX' file
#write.xlsx(waterflow_all, file = file, sheetName = "Combined Waterflow", col.names = TRUE, row.names = FALSE, append = TRUE)
#write.xlsx(preds_ws, file =  file , sheetName = "Forecasts", col.names = TRUE, row.names = FALSE, append = TRUE)

```

